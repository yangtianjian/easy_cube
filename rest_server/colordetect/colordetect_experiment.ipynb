{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Collect dataset\n",
    "&emsp;&emsp; We collect different faces of different cubes in different light colors(ambient) shot by different cameras. \n",
    "To make a dataset easily, we shoot video. In each video, the cube, the face color, the light color and the camera hold same. \n",
    "We only change light intensity. After shooting videos, we tag their labels. Then, we begin make dataset of the cubes."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.1 Clipping videos\n",
    "&emsp;&emsp; Clip the videos in /video directory"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "v_ext_names = ['mov', 'mp4', 'avi']\n",
    "\n",
    "def read_images(video_file_name):\n",
    "    video = cv2.VideoCapture(video_file_name)\n",
    "    frames = []\n",
    "    while True:\n",
    "        success, frame = video.read()\n",
    "        if not success:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    return np.stack(frames, axis=0)\n",
    "\n",
    "def handle_video(v_name):\n",
    "    v_path = os.path.join('video', v_name)\n",
    "    pic_path = os.path.join('video_frames', v_name)\n",
    "    frames = read_images(v_path)\n",
    "    frames_count = frames.shape[0]\n",
    "    for i in np.arange(frames_count):\n",
    "        frame = frames[i]\n",
    "        cv2.imwrite(os.path.join(pic_path, str(i) + '.png'), frame)\n",
    "\n",
    "pool = Pool(processes=8)\n",
    "video_names = list(filter(lambda x: ('.' in x) and (x.split('.')[-1].lower() in v_ext_names) , os.listdir('./video')))\n",
    "for v_name in video_names:\n",
    "    pool.apply_async(handle_video, args=(v_name,))\n",
    "pool.close()\n",
    "pool.join()\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1.2 Rubik's cube separation\n",
    "&emsp;&emsp; Separate rubik cube in the pictures and generate labels in 'label' directory."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Please wait\n",
      "Finish\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def clip_one_picture(picture_file, ux, uy, dx, dy, output_file):\n",
    "    img = cv2.imread(picture_file)\n",
    "    img = img[ux: dx + 1, uy: dy + 1, :]\n",
    "    cv2.imwrite(output_file, img)\n",
    "\n",
    "def list_images(dir_name):\n",
    "    img_suffix = ['png', 'jpg']\n",
    "    images = filter(lambda x: '.' in x and x.split('.')[-1].lower() in img_suffix, os.listdir(dir_name))\n",
    "    return list(images)\n",
    "\n",
    "def clip_multiple_pictures(input_file_names, ux, uy, dx, dy, output_dir_name, start_number):\n",
    "    idx = start_number\n",
    "    for img_file_name in input_file_names:\n",
    "        img_out_name0 = os.path.join(output_dir_name, str(idx)) + '.png'\n",
    "        clip_one_picture(img_file_name, ux, uy, dx, dy, img_out_name0)\n",
    "        idx += 1\n",
    "    \n",
    "print(\"Please wait\")\n",
    "\n",
    "video_dir_names = filter(lambda x: '.' in x and x.split('.')[-1].lower() == 'mov', os.listdir('video_frames'))\n",
    "tb_video = pd.read_csv('./label/label_video.tsv', sep='\\t', index_col='id',\n",
    "                       dtype={'id': int})\n",
    "# tb_picture = pd.DataFrame(columns=['id', 'camera', 'light_color', 'cube_id', 'cube_color', \n",
    "#                                    'video_file_name', 'picture_file_name'], index=['id'])\n",
    "tb_picture = []\n",
    "pool = Pool(8)\n",
    "\n",
    "dict_video_file_name_to_info = dict()\n",
    "columns = ['camera', 'light_color', 'cube_id', 'cube_color', 'file_name', 'ux', 'uy', 'dx', 'dy']\n",
    "ids = list(tb_video.index)\n",
    "for i in range(len(tb_video)):\n",
    "    file_name = tb_video.loc[ids[i], 'file_name']\n",
    "    dict_video_file_name_to_info[file_name] = {}\n",
    "    for c in columns:\n",
    "        dict_video_file_name_to_info[file_name][c] = tb_video.loc[ids[i], c]\n",
    "\n",
    "MULTITHREAD = True\n",
    "i = 0\n",
    "for video_dir_name in video_dir_names:\n",
    "    video_dir_name0 = os.path.join('video_frames', video_dir_name)\n",
    "    image_file_mames = list_images(video_dir_name0)\n",
    "    input_file_names = [os.path.join(video_dir_name0, name) for name in image_file_mames]\n",
    "    endi = i + len(image_file_mames)\n",
    "    \n",
    "    if video_dir_name not in dict_video_file_name_to_info:  # some videos in video_frames directory may not have been labeled\n",
    "        continue\n",
    "    info = dict_video_file_name_to_info[video_dir_name]\n",
    "    if MULTITHREAD:\n",
    "        pool.apply_async(clip_multiple_pictures, args=(input_file_names, info['ux'], info['uy'], \n",
    "                                                       info['dx'], info['dy'], 'clipped_video_frames', i))\n",
    "    else:\n",
    "        clip_multiple_pictures(input_file_names, info['ux'], info['uy'], info['dx'], info['dy'], \n",
    "                               'clipped_video_frames', i)\n",
    "    for j in np.arange(i, endi):\n",
    "        pic_info = info.copy()\n",
    "        pic_info.pop('file_name')\n",
    "        pic_info.pop('ux')\n",
    "        pic_info.pop('uy')\n",
    "        pic_info.pop('dx')\n",
    "        pic_info.pop('dy')\n",
    "        pic_info['video_file_name'] = info['file_name']\n",
    "        pic_info['picture_file_name'] = str(j) + '.png'\n",
    "        pic_info['id'] = j\n",
    "        tb_picture.append(pic_info)\n",
    "    i = endi\n",
    "\n",
    "tb_picture = pd.DataFrame.from_records(tb_picture, index=['id'])\n",
    "\n",
    "pool.close()\n",
    "pool.join()\n",
    "tb_picture.to_csv('./label/label_picture.tsv', sep='\\t')\n",
    "print(\"Finish\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1.3 Rubik's cube color block separation\n",
    "&emsp;&emsp; In this subsection, we separate color blocks in the rubik cube. And by the way generate the label of those \n",
    "color blocks. Hence, we will have a block dataset of the rubik's cube."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Finish\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "\n",
    "def cut3x3(picture_file, output_directory, start_number):\n",
    "    img = cv2.imread(picture_file)\n",
    "    h, w, c = img.shape\n",
    "    h0 = h // 3\n",
    "    w0 = w // 3\n",
    "    k = start_number\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            img2 = img[i * h0: (i + 1) * h0, j * w0: (j + 1) * w0, :]\n",
    "            cv2.imwrite(os.path.join(output_directory, str(k)) + '.png', img2)\n",
    "            k += 1\n",
    "\n",
    "label_pictures = pd.read_csv('./label/label_picture.tsv', sep='\\t', index_col='id')\n",
    "\n",
    "label_blocks = []\n",
    "columns = label_pictures\n",
    "ids = label_pictures.index\n",
    "\n",
    "pool = Pool(8)\n",
    "\n",
    "position_strings = ['UL', 'UM', 'UR', 'ML', 'MM', 'MR', 'DL', 'DM', 'DR']\n",
    "\n",
    "k = 0\n",
    "MULTITHREAD = True\n",
    "for i in range(len(label_pictures)):\n",
    "    file_name = label_pictures.loc[ids[i], 'picture_file_name']\n",
    "    picture_file = os.path.join('./clipped_video_frames', file_name)\n",
    "    if MULTITHREAD:\n",
    "        pool.apply_async(cut3x3, args=(picture_file, './clipped_color_blocks', k))\n",
    "    else:\n",
    "        cut3x3(picture_file, './clipped_color_blocks', k)\n",
    "    \n",
    "    record = label_pictures.loc[ids[i]].to_dict()\n",
    "    for j in range(9):\n",
    "        record2 = record.copy()\n",
    "        record2['block_file_name'] = str(k + j) + '.png'\n",
    "        record2['block_position'] = position_strings[j]\n",
    "        record2['id'] = k + j\n",
    "        label_blocks.append(record2)    \n",
    "    k += 9\n",
    "\n",
    "label_blocks = pd.DataFrame.from_records(label_blocks, index=['id'])\n",
    "label_blocks.to_csv('./label/label_block.tsv', sep='\\t')\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print(\"Finish\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Plot the histograms of different cubes\n",
    "\n",
    " &emsp;&emsp; In colordetect/data folder, we have examples of red cube, blue cube, and green cube. In each of these directory, \n",
    " we present different cubes.  \n",
    " &emsp;&emsp; After that, we write functions to identify color.\n",
    " "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Detect the color sequence of the cube, given an image array that has been selected."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def detect_color(img_arr):\n",
    "    c, w, h = img_arr.shape\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [
     "\n"
    ],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}